{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################\n",
    "# Anisotropic Diffusion Filtering (ADF) method\n",
    "# ################################################\n",
    "def ADFCorrection(imagePath):\n",
    "    # Load the MRI image\n",
    "    image_data = nib.load(imagePath).get_fdata()\n",
    "    # Apply Anisotropic Diffusion Filtering\n",
    "    filtered_image_data = anisotropic_diffusion(mri_image_data, niter=10, kappa=20, option=1)\n",
    "\n",
    "    # Save the filtered image\n",
    "    filtered_image = nib.Nifti1Image(filtered_image_data, affine=nib.load(mri_image_path).affine)\n",
    "    nib.save(filtered_image, imagePath)\n",
    "\n",
    "# ################################################\n",
    "# N4偏置场矫正和ADF降噪\n",
    "# ################################################\n",
    "def N4BiasFieldCorrection(imagePath,saveMaskOrNot):\n",
    "    # 读nifty\n",
    "    input_image = sitk.ReadImage(imagePath)\n",
    "    # 设置蒙版，只对蒙版内的部分操作\n",
    "    mask_image = sitk.OtsuThreshold(input_image,0,1,200)\n",
    "    input_image = sitk.Cast(input_image, sitk.sitkFloat32)\n",
    "    # 主运行\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter() # N4偏置场\n",
    "    output_image = corrector.Execute(input_image,mask_image)\n",
    "    output_image = sitk.Cast(output_image, sitk.sitkInt16)\n",
    "    \n",
    "    # 设置导出文件名\n",
    "    output_path = ''\n",
    "    output_mask_path=''\n",
    "    if imagePath[-7:]=='.nii.gz':\n",
    "        output_path = imagePath[:-7]+'_N4.nii.gz'\n",
    "        output_mask_path = imagePath[:-7]+'_N4_mask.nii.gz'\n",
    "    elif imagePath[-4:]=='.nii':\n",
    "        output_path = imagePath[:-4]+'_N4.nii.gz'\n",
    "        output_mask_path = imagePath[:-4]+'_N4_mask.nii.gz'\n",
    "    else:\n",
    "        print('文件类型错误')\n",
    "        \n",
    "    if saveMaskOrNot:\n",
    "        sitk.WriteImage(mask_image, output_mask_path)\n",
    "    sitk.WriteImage(output_image, output_path)\n",
    "        \n",
    "    print(f'【N4 processed successfully】{imagePath}')\n",
    "    \n",
    "    \n",
    "# ################################################\n",
    "# 强度归一化\n",
    "# ################################################\n",
    "\n",
    "# 数据标准化\n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "# 设置重要的元数据：origin、Direction、Spacing，并返回已经含它们了的SimpleITK格式数据，以便做保存NII等处理\n",
    "def setMetaMessage(target, origin):\n",
    "    target.SetDirection(origin.GetDirection())\n",
    "    target.SetOrigin(origin.GetOrigin())\n",
    "    target.SetSpacing(origin.GetSpacing())\n",
    "    return target\n",
    "\n",
    "# 主程序\n",
    "def signalStrengthNormalization(imagePath):\n",
    "    # 查看原始的维度信息\n",
    "    sitk_img = sitk.ReadImage(imagePath)     # <class 'SimpleITK.SimpleITK.Image'>\n",
    "    img = sitk.GetArrayFromImage(sitk_img)       # <class 'numpy.ndarray'>\n",
    "    # print('原始维度：%s \\n体素大小：%s'%(str(img.shape),str(sitk_img.GetSpacing())))   # (92, 210, 190) (1.0, 1.0, 1.0)\n",
    "    \n",
    "    # 标准化\n",
    "    img_std = np.resize(standardization(img.flatten()),img.shape)\n",
    "\n",
    "    # 变成原始的nifty维度\n",
    "    imgData_Processed = sitk.GetImageFromArray(img_std)\n",
    "    imgData_Processed = setMetaMessage(imgData_Processed, sitk_img)\n",
    "    \n",
    "    # 设置导出文件名\n",
    "    output_path = ''\n",
    "    if imagePath[-7:]=='.nii.gz':\n",
    "        output_path = imagePath[:-7]+'_Zscored.nii.gz'\n",
    "    elif imagePath[-4:]=='.nii':\n",
    "        output_path = imagePath[:-4]+'_Zscored.nii.gz'\n",
    "    else:\n",
    "        print('文件类型错误')\n",
    "\n",
    "    sitk.WriteImage(imgData_Processed, output_path)\n",
    "    print(f'【Normalization processed successfully】{imagePath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取真正的根目录\n",
    "root_path = r'C:\\Users\\euma7\\Desktop\\demo'\n",
    "\n",
    "# 获取根目录下所有文件夹\n",
    "Level_1_name = next(os.walk(root_path))[1]\n",
    "Level_1_path = [root_path+os.sep+i for i in Level_1_name]\n",
    "# Level_1_path = [root_path+os.sep+i+os.sep+\"MR\" for i in Level_1_name]\n",
    "\n",
    "# 下一级目录\n",
    "Level_2_name = []   # 第二级目录的文件名\n",
    "Level_2_path = []   # 第二级目录的文件目录名\n",
    "for i in Level_1_path:\n",
    "    tem = next(os.walk(i))[1]\n",
    "    # print(f'{i}\\n各第二级目录下文件/文件夹为：{tem}\\n')\n",
    "    Level_2_name.append(tem)\n",
    "\n",
    "    for j in tem:\n",
    "        Level_2_path.append(i+os.sep+j)\n",
    "\n",
    "# 所有第二级目录为\n",
    "print(len(Level_2_path))\n",
    "Level_2_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N4偏置场矫正(先运行这个)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取二级目录下的目标文件\n",
    "Level_aim_path = Level_2_path\n",
    "label_file_path_list = []\n",
    "\n",
    "for i in Level_aim_path:\n",
    "    print(f'【父目录】\\n{i}')\n",
    "    childFileList = list(next(os.walk(i))[2])\n",
    "    print(f'父目录下有以下文件{childFileList}')\n",
    "    \n",
    "\n",
    "    targetFileName_A=['t1.nii.gz','t1ce.nii.gz','t2.nii.gz','t2flair.nii.gz']\n",
    "    fileToBeProcessed_N4_list = []\n",
    "    for fname in targetFileName_A:\n",
    "        if fname in childFileList:\n",
    "            fileToBeProcessed_N4 =os.path.join(i,fname)\n",
    "            fileToBeProcessed_N4_list.append(fileToBeProcessed_N4)\n",
    "            \n",
    "    print(fileToBeProcessed_N4_list)    # 要被处理的nifty文件列表\n",
    "    # 开始处理\n",
    "    for imagePath in fileToBeProcessed_N4_list:\n",
    "        ADFCorrection(imagePath)\n",
    "        N4BiasFieldCorrection(imagePath,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 强度标准化（再运行这个）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取二级目录下的目标文件\n",
    "Level_aim_path = Level_2_path\n",
    "label_file_path_list = []\n",
    "\n",
    "for i in Level_aim_path:\n",
    "    print(f'【父目录】\\n{i}')\n",
    "    childFileList = list(next(os.walk(i))[2])\n",
    "    print(f'父目录下有以下文件{childFileList}')\n",
    "\n",
    "    targetFileName_B=['t1_N4.nii.gz','t1ce_N4.nii.gz','t2_N4.nii.gz','t2flair_N4.nii.gz']\n",
    "    fileToBeProcessed_norm_list = []\n",
    "    for fname in targetFileName_B:\n",
    "        if fname in childFileList:\n",
    "            fileToBeProcessed_norm =os.path.join(i,fname)\n",
    "            fileToBeProcessed_norm_list.append(fileToBeProcessed_norm)\n",
    "            \n",
    "#     print(fileToBeProcessed_norm_list)    # 要被处理的nifty文件列表\n",
    "    # 开始处理\n",
    "    for imagePath in fileToBeProcessed_norm_list:\n",
    "        signalStrengthNormalization(imagePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
